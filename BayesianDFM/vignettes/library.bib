% Encoding: UTF-8

@article{Kim1998,
author = {Kim, Sangjoon and Sheppard, Neil and Chibb, Siddhartha},
file = {:Users/Florian/Documents/Literature/Kim, Sheppard, Chibb - 1998 - Stochastic Volatility Likelihood Inference and Comparison with ARCH Models.pdf:pdf},
journal = {Review of Economic Studies},
number = {65},
pages = {159--192},
title = {{Stochastic Volatility: Likelihood Inference and Comparison with ARCH Models}},
volume = {1998},
year = {1998}
}
@article{Stock2012,
abstract = {This paper provides a simple shrinkage representation that describes the operational characteristics of various forecasting methods designed for a large number of orthogonal predictors (such as principal components). These methods include pretest methods, Bayesian model averaging, empirical Bayes, and bagging. We compare empirically forecasts from these methods to dynamic factor model (DFM) forecasts using a U.S. macroeconomic data set with 143 quarterly variables spanning 1960-2008. For most series, including measures of real economic activity, the shrinkage forecasts are inferior to the DFM forecasts},
author = {Stock, James H. and Watson, Mark W.},
doi = {10.1080/07350015.2012.715956},
file = {:Users/Florian/Documents/Literature/Stock, Watson - 2012 - Generalized shrinkage methods for forecasting using many predictors.pdf:pdf},
isbn = {0735-0015$\backslash$r1537-2707},
issn = {0735-0015},
journal = {Journal of Business and Economic Statistics},
keywords = {dynamic factor models,empirical Bayes,high dimensional model},
number = {4},
pages = {481--493},
title = {{Generalized shrinkage methods for forecasting using many predictors}},
url = {http://amstat.tandfonline.com/doi/abs/10.1080/07350015.2012.715956},
volume = {30},
year = {2012}
}
@article{Makridakis2020,
abstract = {This paper provides a non-systematic review of the progress of forecasting in social settings. It is aimed at someone outside the field of forecasting who wants to understand and appreciate the results of the M4 Competition, and forms a survey paper regarding the state of the art of this discipline. It discusses the recorded improvements in forecast accuracy over time, the need to capture forecast uncertainty, and things that can go wrong with predictions. Subsequently, the review classifies the knowledge achieved over recent years into (i) what we know, (ii) what we are not sure about, and (iii) what we don't knowIn the first two areas, we explore the difference between explanation and prediction, the existence of an optimal model, the performance of machine learning methods on time series forecasting tasks, the difficulties of predicting non-stable environments, the performance of judgment, and the value added by exogenous variables. The article concludes with the importance of (thin and) fat tails, the challenges and advances in causal inference, and the role of luck.},
author = {Makridakis, Spyros and Hyndman, Rob J. and Petropoulos, Fotios},
doi = {10.1016/j.ijforecast.2019.05.011},
file = {:Users/Florian/Documents/Literature/Makridakis, Hyndman, Petropoulos - 2020 - Forecasting in social settings The state of the art.pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {Accuracy,Causality,Judgment,Knowns and unknowns,Machine Learning,Review,Uncertainty},
number = {1},
pages = {15--28},
publisher = {Elsevier B.V.},
title = {{Forecasting in social settings: The state of the art}},
url = {https://doi.org/10.1016/j.ijforecast.2019.05.011},
volume = {36},
year = {2020}
}
@article{Change2015,
abstract = {In this paper, we propose a time-varying parameter VAR model with stochastic volatility which allows for estimation on data sampled at different frequencies. Our contribution is two- fold. First, we extend the methodology developed by Cogley and Sargent (2005), and Primiceri (2005), to a mixed-frequency setting. In particular, our approach allows for the inclusion of two different categories of variables (high-frequency and low-frequency) into the same time varying model. Second, we use this model to study the macroeconomic effects of government spending shocks in Italy over the 1988Q4-2013Q3 period. Italy - as well as most other euro area economies - is characterised by short quarterly time series for fiscal variables, whereas annual data are generally available for a longer sample before 1999. Our results show that the proposed time- varying mixed-frequency model improves on the performance of a simple linear interpolation model in generating the true path of the missing observations. Second, our empirical analysis suggests that government spending shocks tend to have positive effects on output in Italy. The fiscal multiplier, which is maximized at the one year horizon, follows a U-shape over the sample considered: it peaks at around 1.5 at the beginning of the sample, it then stabilizes between 0.8 and 0.9 from the mid-1990s to the late 2000s, before rising again to above unity during of the recent crisis.},
author = {Cimadomo, Jacopo and D'Agostino, Antonello},
doi = {10.2866/991811},
file = {:Users/Florian/Documents/Literature/Cimadomo, D'Agostino - 2015 - Combining time-variation and mixed-frequencies an analysis of government spending multipliers in Italy.pdf:pdf},
journal = {European Central Bank, Working Paper},
keywords = {Time variation,government s,mixed-frequency data},
number = {October},
title = {{Combining time-variation and mixed-frequencies: an analysis of government spending multipliers in Italy}},
url = {https://ideas.repec.org/s/ecb/ecbwps.html.},
volume = {1856},
year = {2015}
}
@article{Marcellino2016a,
abstract = {In this article, we develop a mixed frequency dynamic factor model in which the disturbances of both the latent common factor and of the idiosyncratic components have time-varying stochastic volatilities. We use the model to investigate business cycle dynamics in the euro area and present three sets of empirical results. First, we evaluate the impact of macroeconomic releases on point and density forecast accuracy and on the width of forecast intervals. Second, we show how our setup allows to make a probabilistic assessment of the contribution of releases to forecast revisions. Third, we examine point and density out of sample forecast accuracy. We find that introducing stochastic volatility in the model contributes to an improvement in both point and density forecast accuracy. Supplementary materials for this article are available online.},
author = {Marcellino, Massimiliano and Porqueddu, Mario and Venditti, Fabrizio},
doi = {10.1080/07350015.2015.1006773},
file = {:Users/Florian/Documents/Literature/Marcellino, Porqueddu, Venditti - 2016 - Short-Term GDP Forecasting With a Mixed-Frequency Dynamic Factor Model With Stochastic Volat(2).pdf:pdf},
issn = {15372707},
journal = {Journal of Business and Economic Statistics},
keywords = {Business cycle,Mixed-frequency data,Nonlinear models,Nowcasting},
number = {1},
pages = {118--127},
title = {{Short-Term GDP Forecasting With a Mixed-Frequency Dynamic Factor Model With Stochastic Volatility}},
volume = {34},
year = {2016}
}
@article{Aruoba2009a,
abstract = {We construct a framework for measuring economic activity at high frequency, potentially in real time.We use a variety of stock and flow data observed at mixed frequencies (including very high frequencies), and we use a dynamic factor model that permits exact filtering. We illustrate the framework in a prototype empirical example and a simulation study calibrated to the example. {\textcopyright} 2009 American Statistical Association.},
author = {Aruoba, S. Boraǧan and Diebold, Francis X. and Scotti, Chiara},
doi = {10.1198/jbes.2009.07205},
file = {:Users/Florian/Documents/Literature/Aruoba, Diebold, Scotti - 2009 - Real-time measurement of business conditions(2).pdf:pdf},
issn = {07350015},
journal = {Journal of Business and Economic Statistics},
keywords = {Business cycle,Contraction,Dynamic factor model,Expansion,Macroeconomic forecasting,Recession,State space model,Turning point},
number = {4},
pages = {417--427},
title = {{Real-time measurement of business conditions}},
volume = {27},
year = {2009}
}
@article{Bai2013a,
abstract = {We examine the relationship between Mi(xed) Da(ta) S(ampling) (MIDAS) regressions and the Kalman filter when forecasting with mixed frequency data. In general, state space models involve a system of equations, whereas MIDAS regressions involve a single equation. As a consequence, MIDAS regressions might be less efficient, but could also be less prone to parameter estimation error and/or specification errors. We examine how MIDAS regressions and Kalman filters match up under ideal circumstances, that is in population, and in cases where all the stochastic processes—low and high frequency—are correctly specified. We characterize cases where the MIDAS regression exactly replicates the steady state Kalman filter weights. We compare MIDAS and Kalman filter forecasts in population where the state space model is misspecified. We also compare MIDAS and Kalman filter forecasts in small samples. The paper concludes with an empirical application. Overall we find that the MIDAS and Kalman filter methods give similar ...},
author = {Bai, Jennie and Ghysels, Eric and Wright, Jonathan H.},
doi = {10.1080/07474938.2012.690675},
file = {:Users/Florian/Documents/Literature/Bai, Ghysels, Wright - 2013 - State Space Models and MIDAS Regressions.pdf:pdf},
issn = {0747-4938},
journal = {Econometric Reviews},
keywords = {C22,C52,Kalman filter,Mixed frequency data},
number = {7},
pages = {779--813},
title = {{State Space Models and MIDAS Regressions}},
url = {http://www.tandfonline.com/doi/abs/10.1080/07474938.2012.690675},
volume = {32},
year = {2013}
}
@article{Ghysels2014,
author = {Ghysels, Eric},
file = {:Users/Florian/Documents/Literature/Ghysels - 2014 - Matlab Toolbox for Mixed Sampling Frequency Data Analysis using MIDAS Regression Models.pdf:pdf},
journal = {University of North Carolina Working Paper},
pages = {1--35},
title = {{Matlab Toolbox for Mixed Sampling Frequency Data Analysis using MIDAS Regression Models}},
year = {2014}
}
@article{Bai2015,
abstract = {We consider a set of minimal identification conditions for dynamic factor models. These conditions have economic interpretations and require fewer number of restrictions than the static factor framework. Under these restric- tions, a standard structural vector autoregression (SVAR) with measurement errors can be embedded into a dynamic factor model. More generally, we also consider overidentification restrictions to achieve efficiency. General lin- ear restrictions, either in the form of known factor loadings or cross-equation restrictions, are considered. We further consider serially correlated idiosyn- cratic errors with heterogeneous coefficients. A numerically stable Bayesian algorithm for the dynamic factor model with general parameter restrictions is constructed for estimation and inference. A square-root form of Kalman filter is shown to improve robustness and accuracy when sampling the latent factors. Confidence intervals (bands) for the parameters of interest such as impulse responses are readily computed. Similar identification conditions are also exploited for multi-level factor models, and they allow us to study the “spill-over” effects of the shocks arising from one group to another. Key},
archivePrefix = {arXiv},
arxivId = {suresh govindarajan},
author = {Bai, Jushan and Wang, Peng},
doi = {10.1080/07350015.2014.941467},
eprint = {suresh govindarajan},
file = {:Users/Florian/Documents/Literature/Bai, Wang - 2015 - Identification and Estimation of Dynamic Factor Models(2).pdf:pdf},
isbn = {9781905846498},
issn = {15372707},
journal = {Journal of Business {\&} Economic Statistics},
keywords = {Dynamic factor models,Impulse response function,Multi-level factor model,Spill-over effect},
number = {2},
pages = {221--240},
pmid = {910},
title = {{Identification and Estimation of Dynamic Factor Models}},
volume = {33},
year = {2015}
}
@article{Rodriguez2010,
author = {Rodriguez, Abel and Puggioni, Gavino},
doi = {10.1016/j.ijforecast.2010.01.009},
file = {:Users/Florian/Documents/Literature/Rodriguez, Puggioni - 2010 - Mixed Frequency Models Bayesian Approaches to Estimation and Prediction.pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {gross national product,interest rates,mixed frequency data,model averaging,model selection},
month = {apr},
number = {2},
pages = {293--311},
publisher = {Elsevier B.V.},
title = {{Mixed Frequency Models: Bayesian Approaches to Estimation and Prediction}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0169207010000154},
volume = {26},
year = {2010}
}
@article{Kaiser1958,
abstract = {An analytic criterion for rotation is defined. The scientific advantage of analytic criteria over subjective (graphical) rotational procedures is discussed. Carroll's criterion and the quartimax criterion are briefly reviewed; the varimax criterion is outlined in detail and contrasted both logically and numerically with the quartimax criterion. It is shown that the normal varimax solution probably coincides closely to the application of the principle of simple structure. However, it is proposed that the ultimate criterion of a rotational procedure is factorial invariance, not simple structure-although the two notions appear to be highly related. The normal varimax criterion is shown to be a two-dimensional generalization of the classic Spearman case, i.e., it shows perfect factorial invariance for two pure clusters. An example is given of the invariance of a normal varimax solution for more than two factors. The oblique normal varimax criterion is stated. A computational outline for the orthogonal normal varimax is appended. {\textcopyright} 1958 Psychometric Society.},
author = {Kaiser, Henry F.},
doi = {10.1007/BF02289233},
file = {:Users/Florian/Documents/Literature/Kaiser - 1958 - The varimax criterion for analytic rotation in factor analysis.pdf:pdf},
issn = {00333123},
journal = {Psychometrika},
number = {3},
pages = {187--200},
title = {{The varimax criterion for analytic rotation in factor analysis}},
volume = {23},
year = {1958}
}
@article{Rudebusch1998b,
author = {Rudebusch, Glenn D.},
file = {:Users/Florian/Documents/Literature/Rudebusch - 1998 - Do Measures of Monetary Policy in a Var Make Sense A Reply to Christopher A. Sims.pdf:pdf},
journal = {International Economic Review},
number = {4},
pages = {943--948},
title = {{Do Measures of Monetary Policy in a Var Make Sense? A Reply to Christopher A. Sims}},
volume = {39},
year = {1998}
}
@article{Sims1991,
author = {Sims, Christopher A. and Uhlig, Harald},
file = {:Users/Florian/Documents/Literature/Sims, Uhlig - 1991 - Understanding Unit Rooters A Helicopter Tour.pdf:pdf},
journal = {Econometrica},
number = {6},
pages = {1591--1599},
title = {{Understanding Unit Rooters: A Helicopter Tour}},
volume = {59},
year = {1991}
}
@article{Banbura2014,
author = {Banbura, Marta and Modugno, Michele},
doi = {10.1002/jae},
file = {:Users/Florian/Documents/Literature/Banbura, Modugno - 2014 - Maximum Likelihood Estimation of Factor Models with Arbitrary Patterns of Missing Data.pdf:pdf},
issn = {01451707},
journal = {Journal of Applied Econometrics},
number = {1},
pages = {133--160},
title = {{Maximum Likelihood Estimation of Factor Models with Arbitrary Patterns of Missing Data}},
volume = {29},
year = {2014}
}
@article{Sims1988,
author = {Sims, Christopher A},
file = {:Users/Florian/Documents/Literature/Sims - 1988 - Bayesian Skepticism on Unit Root Econometrics.pdf:pdf},
pages = {463--474},
title = {{Bayesian Skepticism on Unit Root Econometrics}},
volume = {12},
year = {1988}
}
@article{Kaufmann2019,
abstract = {Common variation in N series is extracted into k«N dynamic factors. We induce sparsity by using a zero point mass–normal mixture prior distribution on the loadings. Estimation and rotational identification are independent of variable ordering. Sparsity helps identifying the factor space and the factors. Rotational identification, including factor order and sign, is obtained by processing the posterior output and based on factor draws rather than factor loading draws. Simulating data, we document sampler and estimation efficiency. To illustrate, we estimate the model for a large panel of Swiss macroeconomic and detailed price data. We identify 16 factors with a clear economic interpretation.},
author = {Kaufmann, Sylvia and Schumacher, Christian},
doi = {10.1016/j.jeconom.2018.11.008},
file = {:Users/Florian/Documents/Literature/Kaufmann, Schumacher - 2019 - Bayesian Estimation of Sparse Dynamic Factor Models with Order-Independent and Ex-Post Mode Identification.pdf:pdf},
issn = {18726895},
journal = {Journal of Econometrics},
keywords = {Ex-post processing,Factor interpretation,Factor order permutation,Large dataset,Rotation},
number = {1},
pages = {116--134},
publisher = {Elsevier B.V.},
title = {{Bayesian Estimation of Sparse Dynamic Factor Models with Order-Independent and Ex-Post Mode Identification}},
url = {https://doi.org/10.1016/j.jeconom.2018.11.008},
volume = {210},
year = {2019}
}
@article{DelNegro2008,
abstract = {We develop a dynamic factor model with time-varying factor loadings and stochastic volatility in both the latent factors and idiosyncratic components. We employ this new measurement tool to study the evolution of international business cycles in the post- Bretton Woods period, using a panel of output growth rates for nineteen countries. We find 1) statistical evidence of a decline in volatility for most countries, with the timing, magnitude, and source (international or domestic) of the decline differing across countries; 2) some evidence of a decline in business cycle synchronization for Group of Seven (G-7) countries, but otherwise no evidence of changes in synchronization for the sample countries, including European and euro-area countries; and 3) convergence in the volatility of business cycles across countries.},
author = {{Del Negro}, Marco and Otrok, Christopher},
file = {:Users/Florian/Documents/Literature/Del Negro, Otrok - 2008 - Dynamic Factor Models with Time-Varying Parameters Measuring Changes in International Business Cycles.pdf:pdf},
journal = {Federal Reserve Bank of New York Staff Reports},
keywords = {Bayesian factor models,G,time-varying parameters},
number = {326},
pages = {1--46},
title = {{Dynamic Factor Models with Time-Varying Parameters: Measuring Changes in International Business Cycles}},
url = {http://www.newyorkfed.org/research/staff{\_}reports/sr326.pdf{\%}5Cnpapers2://publication/uuid/170539DE-BB71-4AE2-82D2-40974713131A},
year = {2008}
}
@article{Forni2005,
abstract = {This article proposes a new forecasting method that makes use of information from a large panel of time series. Like earlier methods, our method is based on a dynamic factor model. We argue that our method improves on a standard principal component predictor in that it fully exploits all the dynamic covariance structure of the panel and also weights the variables according to their estimated signal-to-noise ratio. We provide asymptotic results for our optimal forecast estimator and show that in finite samples, our forecast outperforms the standard principal components predictor.},
author = {Forni, Mario and Hallin, Marc and Lippi, Marco and Reichlin, Lucrezia},
doi = {10.1198/016214504000002050},
file = {:Users/Florian/Documents/Literature/Forni et al. - 2005 - The Generalized Dynamic Factor Model.pdf:pdf},
isbn = {0162-1459},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {dynamic factor model,forecasting,large cross-section,panel data,principal components,time series},
number = {471},
pages = {830--840},
title = {{The Generalized Dynamic Factor Model}},
url = {http://www.tandfonline.com/doi/abs/10.1198/016214504000002050},
volume = {100},
year = {2005}
}
@article{Marcellino2016,
author = {Marcellino, Massimiliano and Porqueddu, Mario and Venditti, Fabrizio},
doi = {10.1080/07350015.2015.1006773},
file = {:Users/Florian/Documents/Literature/Marcellino, Porqueddu, Venditti - 2016 - Short-Term GDP Forecasting With a Mixed-Frequency Dynamic Factor Model With Stochastic Volatili.pdf:pdf},
issn = {0735-0015},
journal = {Journal of Business {\&} Economic Statistics},
keywords = {business cycle,mixed-frequency data,nonlinear models,nowcasting},
number = {1},
pages = {118--127},
title = {{Short-Term GDP Forecasting With a Mixed-Frequency Dynamic Factor Model With Stochastic Volatility}},
url = {http://www.tandfonline.com/doi/full/10.1080/07350015.2015.1006773},
volume = {34},
year = {2016}
}
@article{Stock2002,
abstract = {This article considers forecasting a single time series when there are many predictors (N) and time series observations (T). When the data follow an approximate factor model, the predictors can be summarized by a small number of indexes, which we estimate using principal components. Feasible forecasts are shown to be asymptotically efficient in the sense that the difference between the feasible forecasts and the infeasible forecasts constructed using the actual values of the factors converges in probability to 0 as both N and T grow large. The estimated factors are shown to be consistent, even in the presence of time variation in the factor model.},
author = {Stock, James H. and Watson, Mark W.},
doi = {10.1198/016214502388618960},
file = {:Users/Florian/Documents/Literature/Stock, Watson - 2002 - Forecasting Using Principal Components from a Large Number of Predictors.pdf:pdf},
isbn = {01621459},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {factor models,forecasting,principal components},
number = {460},
pages = {1167--1179},
title = {{Forecasting Using Principal Components from a Large Number of Predictors}},
url = {http://www.jstor.org/stable/3085839},
volume = {97},
year = {2002}
}
@article{Rudebusch1998a,
author = {Rudebusch, Glenn D.},
file = {:Users/Florian/Documents/Literature/Rudebusch - 1998 - Do Monetary Policy in a VAR Make Sense.pdf:pdf},
journal = {International Economic Review},
number = {4},
pages = {907--931},
title = {{Do Monetary Policy in a VAR Make Sense ?}},
volume = {39},
year = {1998}
}
@book{Anderson1956,
author = {Anderson, T. W. and Rubin, Herman},
booktitle = {Proceedings of the Third Berkeley Symposium on Mathematical Statistics and Probability, Volume 5: Contributions to Econometrics, Industrial Research, and Psychometry},
file = {:Users/Florian/Documents/Literature/Anderson, Rubin - 1956 - Statistical Inference in Factor Analysis.pdf:pdf},
title = {{Statistical Inference in Factor Analysis}},
year = {1956}
}
@article{Clements2008,
abstract = {Although many macroeconomic series such as US real output growth are sampled quarterly, many potentially useful predictors are observed at a higher frequency. We look at whether a recently developed mixed data-frequency sampling (MIDAS) approach can improve forecasts of output growth and inflation. We carry out a number of related real-time forecast comparisons using various indicators as explanatory variables. We find that MIDAS model forecasts of output growth are more accurate at horizons less than one quarter using coincident indicators ; that MIDAS models are an effective way of combining information from multiple indicators ; and that the forecast accuracy of the unemployment-rate Phillips curve for inflation is enhanced using the MIDAS approach.},
author = {Clements, Michael P. and Galv{\~{a}}o, Ana Beatriz},
doi = {10.1198/073500108000000015},
file = {:Users/Florian/Documents/Literature/Clements, Galv{\~{a}}o - 2008 - Macroeconomic forecasting with mixed-frequency data Forecasting output growth in the United States.pdf:pdf},
issn = {07350015},
journal = {Journal of Business and Economic Statistics},
keywords = {Forecasting,Mixed-frequency data,U.S. Output growth},
number = {4},
pages = {546--554},
title = {{Macroeconomic forecasting with mixed-frequency data: Forecasting output growth in the United States}},
volume = {26},
year = {2008}
}
@article{Marcellino2016b,
abstract = {Large scale factor models have been often adopted both for forecasting and to identify structural shocks and their transmission mechanism. Mixed frequency factor models have been also used in a reduced form context, but not for structural applications, and in this paper we close this gap. First, we adapt a simple technique developed in a small scale mixed frequency VAR and factor context to the large scale case, and compare the resulting model with existing alternatives. Second, using Monte Carlo experiments, we show that the finite sample properties of the mixed frequency factor model estimation procedure are quite good. Finally, to illustrate the method we present three empirical examples dealing with the effects of, respectively, monetary, oil, and fiscal shocks.},
author = {Marcellino, Massimiliano and Sivec, Vasja},
doi = {10.1016/j.jeconom.2016.04.010},
file = {:Users/Florian/Documents/Literature/Marcellino, Sivec - 2016 - Monetary, fiscal and oil shocks Evidence based on mixed frequency structural FAVARs.pdf:pdf},
isbn = {8152835714},
issn = {18726895},
journal = {Journal of Econometrics},
keywords = {Estimation,Identification,Impulse response function,Mixed frequency data,Structural FAVAR,Temporal aggregation},
number = {2},
pages = {335--348},
title = {{Monetary, fiscal and oil shocks: Evidence based on mixed frequency structural FAVARs}},
volume = {193},
year = {2016}
}
@article{Baffigi2004,
abstract = {Quantitative information on the current state of the economy is crucial to economic policy-making and to early understanding of the economic situation, but the quarterly national account (NA) data for GDP in the euro area are released with a substantial delay. The aim of the paper is to examine the forecast ability of bridge models (BM) for GDP growth in the euro area. BM 'bridge the gap' between the information content of timely updated indicators and the delayed (but more complete) NA. In this paper, BM are estimated for aggregate GDP and components both area-wide and for the three main countries of the euro area. Their short-term (one- and two-quarter ahead) forecasting performance is assessed with respect to benchmark univariate/multivariate statistical models, and a small structural model. The paper shows that national BM fare better than benchmark models. In addition, euro area GDP and its components are more precisely predicted by aggregating national forecasts. {\textcopyright} 2003 International Institute of Forecasters. Published by Elsevier B.V. All rights reserved.},
author = {Baffǐgi, Alberto and Golinelli, Roberto and Parigi, Giuseppe},
doi = {10.1016/S0169-2070(03)00067-0},
file = {:Users/Florian/Documents/Literature/Baffǐgi, Golinelli, Parigi - 2004 - Bridge models to forecast the euro area GDP.pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {Bridge model,Out-of-sample forecasting accuracy,Short-term GDP forecast for the euro area},
number = {3},
pages = {447--460},
title = {{Bridge models to forecast the euro area GDP}},
volume = {20},
year = {2004}
}
@article{Kapetanios2015,
abstract = {Abstract Density forecast combinations are becoming increasingly popular as a means of improving forecast 'accuracy', as measured by a scoring rule. In this paper we generalise this literature by letting the combination weights follow more general schemes. Sieve estimation is used to optimise the score of the generalised density combination where the combination weights depend on the variable one is trying to forecast. Specific attention is paid to the use of piecewise linear weight functions that let the weights vary by region of the density. We analyse these schemes theoretically, in Monte Carlo experiments and in an empirical study. Our results show that the generalised combinations outperform their linear counterparts.},
author = {Kapetanios, G. and Mitchell, J. and Price, S. and Fawcett, N.},
doi = {10.1016/j.jeconom.2015.02.047},
file = {:Users/Florian/Documents/Literature/Kapetanios et al. - 2015 - Generalised Density Forecast Combinations.pdf:pdf},
issn = {18726895},
journal = {Journal of Econometrics},
keywords = {Density forecasting,Model combination,Scoring rules},
number = {1},
pages = {150--165},
publisher = {Elsevier B.V.},
title = {{Generalised Density Forecast Combinations}},
url = {http://dx.doi.org/10.1016/j.jeconom.2015.02.047},
volume = {188},
year = {2015}
}
@article{Chan2017,
author = {Chan, Joshua and Leon-Gonzalez, Roberto and Strachan, Rodney W.},
doi = {10.1080/01621459.2017.1287080},
file = {:Users/Florian/Documents/Literature/Chan, Leon-Gonzalez, Strachan - 2017 - Invariant Inference and Efficient Computation in the Static Factor Model.pdf:pdf},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
pages = {1--27},
title = {{Invariant Inference and Efficient Computation in the Static Factor Model}},
year = {2017}
}
@article{Koop2010,
author = {Koop, Gary and Korobilis, Dimitris},
file = {:Users/Florian/Documents/Literature/Koop, Korobilis - 2010 - Bayesian Multivariate Time Series Methods for Empirical Macroeconomics.pdf:pdf},
journal = {Foundations and Trends in Econometrics},
number = {4},
pages = {267--358},
publisher = {now Publishers, Delft},
title = {{Bayesian Multivariate Time Series Methods for Empirical Macroeconomics}},
volume = {3},
year = {2010}
}
@article{Forni2015,
abstract = {Factor model methods recently have become extremely popular in the theory and practice of large panels of time series data. Those methods rely on various factor models which all are particular cases of the Generalized Dynamic Factor Model (GDFM) introduced in Forniet al. (2000). That paper, however, rests on Brillinger's dynamic principal components. The corresponding estimators are two-sided filters whose performance at the end of the observation period or for forecasting purposes is rather poor. No such problem arises with estimators based on standard principal components, which have been dominant in this literature. On the other hand, those estimators require the assumption that the space spanned by the factors has finite dimension. In the present paper, we argue that such an assumption is extremely restrictive and potentially quite harmful. Elaborating upon recent results by Anderson and Deistler (2008a, b) on singular stationary processes with rational spectrum, we obtain one-sided representations for the GDFM without assuming finite dimension of the factor space. Construction of the corresponding estimators is also briefly outlined. In a companion paper, we establish consistency and rates for such estimators, and provide Monte Carlo results further motivating our approach.},
author = {Forni, Mario and Hallin, Marc and Lippi, Marco and Zaffaroni, Paolo},
doi = {10.1016/j.jeconom.2013.10.017},
file = {:Users/Florian/Documents/Literature/Forni et al. - 2015 - Dynamic Factor Models with Infinite-Dimensional Factor Spaces One-sided Representations.pdf:pdf},
issn = {18726895},
journal = {Journal of Econometrics},
keywords = {Generalized dynamic factor models,One-sided representations for dynamic factor model,Vector processes with singular spectral density},
number = {2},
pages = {359--371},
publisher = {Elsevier B.V.},
title = {{Dynamic Factor Models with Infinite-Dimensional Factor Spaces: One-sided Representations}},
url = {http://dx.doi.org/10.1016/j.jeconom.2013.10.017},
volume = {185},
year = {2015}
}
@article{Timmermann2006,
abstract = {Forecast combinations have frequently been found in empirical studies to produce better forecasts on average than methods based on the ex ante best individual forecasting model. Moreover, simple combinations that ignore correlations between forecast errors often dominate more refined combination schemes aimed at estimating the theoretically optimal combination weights. In this chapter we analyze theoretically the factors that determine the advantages from combining forecasts (for example, the degree of correlation between forecast errors and the relative size of the individual models' forecast error variances). Although the reasons for the success of simple combination schemes are poorly understood, we discuss several possibilities related to model misspecification, instability (non-stationarities) and estimation error in situations where the number of models is large relative to the available sample size. We discuss the role of combinations under asymmetric loss and consider combinations of point, interval and probability forecasts. {\textcopyright} 2006 Elsevier B.V. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Timmermann, Allan},
doi = {10.1016/S1574-0706(05)01004-9},
eprint = {arXiv:1011.1669v3},
file = {:Users/Florian/Documents/Literature/Timmermann - 2006 - Forecast Combinations.pdf:pdf},
isbn = {9780444513953},
issn = {15740706},
journal = {Handbook of Economic Forecasting},
keywords = {diversification gains,forecast combinations,model misspecification,pooling and trimming,shrinkage methods},
number = {05},
pages = {135--196},
pmid = {25246403},
title = {{Forecast Combinations}},
volume = {1},
year = {2006}
}
@article{Grassi2015,
abstract = {This paper deals with the estimation of monthly indicators of economic activity for the Euro area and its largest member countries that possess the following attributes: relevance, representativeness and timeliness. Relevance is determined by comparing our monthly indicators to the gross domestic product at chained volumes, as the most important measure of the level of economic activity. Representativeness is achieved by considering a very large number of (timely) time series of monthly indicators relating to the level of economic activity, providing a more or less complete coverage. The indicators are modelled using a large-scale parametric factor model. We discuss its specification and provide details of the statistical treatment. Computational efficiency is crucial for the estimation of large-scale parametric factor models of the dimension used in our application (considering about 170 series). To achieve it, we apply state-of-the-art state space methods that can handle temporal aggregation, and any pattern of missing values.},
author = {Grassi, Stefano and Proietti, Tommaso and Frale, Cecilia and Marcellino, Massimiliano and Mazzi, Gianluigi},
doi = {10.1016/j.ijforecast.2014.08.015},
file = {:Users/Florian/Documents/Literature/Grassi et al. - 2015 - EuroMInd-C A disaggregate monthly indicator of economic activity for the Euro area and member countries.pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {Dynamic factor models,Index of coincident indicators,Multivariate state space models,Quarterly national accounts,Temporal disaggregation},
number = {3},
pages = {712--738},
publisher = {Elsevier B.V.},
title = {{EuroMInd-C: A disaggregate monthly indicator of economic activity for the Euro area and member countries}},
url = {http://dx.doi.org/10.1016/j.ijforecast.2014.08.015},
volume = {31},
year = {2015}
}
@article{Schumacher2008,
abstract = {This paper discusses a factor model for short-term forecasting of GDP growth using a large number of monthly and quarterly time series in real-time. To take into account the different periodicities of the data and missing observations at the end of the sample, the factors are estimated by applying an EM algorithm, combined with a principal components estimator. We discuss some in-sample properties of the estimator in a real-time environment and propose alternative methods for forecasting quarterly GDP with monthly factors. In the empirical application, we use a novel real-time dataset for the German economy. Employing a recursive forecast experiment, we evaluate the forecast accuracy of the factor model with respect to German GDP. Furthermore, we investigate the role of revisions in forecast accuracy and assess the contribution of timely monthly observations to the forecast performance. Finally, we compare the performance of the mixed-frequency model with that of a factor model, based on time-aggregated quarterly data. ?? 2008 International Institute of Forecasters.},
author = {Schumacher, Christian and Breitung, J{\"{o}}rg},
doi = {10.1016/j.ijforecast.2008.03.008},
file = {:Users/Florian/Documents/Literature/Schumacher, Breitung - 2008 - Real-time forecasting of German GDP based on a large factor model with monthly and quarterly data.pdf:pdf},
isbn = {0169-2070},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {C53,E37,EM algorithm,Factor models,Forecasting,GDP,Principal components},
number = {3},
pages = {386--398},
title = {{Real-time forecasting of German GDP based on a large factor model with monthly and quarterly data}},
volume = {24},
year = {2008}
}
@article{Bai2017,
abstract = {It is known that the common factors in a large panel of data can be consistently estimated by the method of principal components, and principal components can be constructed by iterative least squares regressions. Replacing least squares with ridge regressions turns out to have the effect of shrinking the singular values of the common component and possibly reducing its rank. The method is used in the machine learning literature to recover low-rank matrices. We study the procedure from the perspective of estimating a minimum-rank approximate factor model. We show that the constrained factor estimates are biased but can be more efficient in terms of mean-squared errors. Rank consideration suggests a data-dependent penalty for selecting the number of factors. The new criterion is more conservative in cases when the nominal number of factors is inflated by the presence of weak factors or large measurement noise. The framework is extended to incorporate a priori linear constraints on the loadings. We provide asymptotic results that can be used to test economic hypotheses.},
archivePrefix = {arXiv},
arxivId = {1708.08137},
author = {Bai, Jushan and Ng, Serena},
eprint = {1708.08137},
file = {:Users/Florian/Documents/Literature/Bai, Ng - 2017 - Principal Components and Regularized Estimation of Factor Models.pdf:pdf},
keywords = {low rank decomposi-,robust principal components,singular-value thresholding},
title = {{Principal Components and Regularized Estimation of Factor Models}},
url = {http://arxiv.org/abs/1708.08137},
volume = {1658770},
year = {2017}
}
@article{Banbura2013,
abstract = {The term now-casting is a contraction for now and forecasting and has been used for a long-time in meteorology and recently also in economics In this paper we survey recent developments on economic now-casting with special focus on those models that formalize key features of how market participants and policy makers read macroeconomic data releases in real time, which involves: monitoring many data, forming expectations about them and revising the assessment on the state of the economy whenever realizations diverge sizeably from those expectations. (This abstract was borrowed from another version of this item.)},
author = {Banbura, Marta and Giannone, Domenico and Modugno, Mich{\`{e}}le and Reichlin, Lucrezia},
doi = {10.1016/B978-0-444-53683-9.00004-9},
file = {:Users/Florian/Documents/Literature/Banbura et al. - 2013 - Now-Casting and the Real-Time Data Flow.pdf:pdf},
isbn = {9780444536839},
journal = {European Central Bank Working Paper Series},
keywords = {Macroeconomic news,macroeconomic forecasting,rea},
number = {15},
title = {{Now-Casting and the Real-Time Data Flow}},
volume = {1564},
year = {2013}
}
@article{Foroni2013,
author = {Foroni, Claudia and Marcellino, Massimiliano},
file = {:Users/Florian/Documents/Literature/Foroni, Marcellino - 2013 - A Survey of Econometric Methods for Mixed-Frequency Data.pdf:pdf},
journal = {Norges Bank Research Paper},
title = {{A Survey of Econometric Methods for Mixed-Frequency Data}},
year = {2013}
}
@article{Mariano2010,
abstract = {The Stock-Watson coincident index and its subsequent extensions assume a static linear one-factor model for the component indicators. This restrictive assumption is unnecessary if one defines a coincident index as an estimate of monthly real gross domestic products (GDP). This paper estimates Gaussian vector autoregression (VAR) and factor models for latent monthly real GDP and other coincident indicators using the observable mixed-frequency series. For maximum likelihood estimation of a VAR model, the expectation-maximization (EM) algorithm helps in finding a good starting value for a quasi-Newton method. The smoothed estimate of latent monthly real GDP is a natural extension of the Stock-Watson coincident index. Copyright (c) Blackwell Publishing Ltd and the Department of Economics, University of Oxford, 2009.},
author = {Mariano, Roberto S. and Murasawa, Yasutomo},
doi = {10.1111/j.1468-0084.2009.00567.x},
file = {:Users/Florian/Documents/Literature/Mariano, Murasawa - 2010 - A Coincident Index, Common Factors, and Monthly Real GDP.pdf:pdf},
issn = {03059049},
journal = {Oxford Bulletin of Economics and Statistics},
number = {1},
pages = {27--46},
title = {{A Coincident Index, Common Factors, and Monthly Real GDP}},
volume = {72},
year = {2010}
}
@article{Andreou2013,
abstract = {We introduce easy to implement regression-based methods for predicting quarterly real economic activity that use daily financial data. Our analysis is designed to elucidate the value of daily information and provide real-time forecast updates of the current (nowcasting) and future quarters. Our findings show that while on average the predictive ability of all models worsens substantially following the financial crisis, the models we propose suffer relatively less losses. Moreover, these predictive gains are primarily driven by the asset classes of government securities, equities, and especially corporate risk.},
author = {Andreou, Elena and Ghysels, Eric and Kourtellos, Andros},
doi = {10.1080/07350015.2013.767199},
file = {:Users/Florian/Documents/Literature/Andreou, Ghysels, Kourtellos - 2013 - Should Macroeconomic Forecasters Use Daily Financial Data and How.pdf:pdf},
isbn = {0735-0015$\backslash$r1537-2707},
issn = {07350015},
journal = {Journal of Business and Economic Statistics},
keywords = {Daily financial factors,Financial markets and the macroeconomy,MIDAS regressions},
number = {2},
pages = {240--251},
title = {{Should Macroeconomic Forecasters Use Daily Financial Data and How?}},
volume = {31},
year = {2013}
}
@article{Stock2002b,
abstract = {This article studies forecasting a macroeconomic time series variable using a large number of predictors. The predictors are summarized using a small number of indexes constructed by principal component analysis. An approximate dynamic factor model serves as the statistical framework for the estimation of the indexes and construction of the forecasts. The method is used to construct 6-, 12-, and 24-month-ahead forecasts for eight monthly U.S. macroeconomic time series using 215 predictors in simulated real time from 1970 through 1998. During this sample period these new forecasts outperformed univariate autoregressions, small vector autoregressions, and leading indicator models.},
author = {Stock, James H. and Watson, Mark W.},
doi = {10.1198/073500102317351921},
file = {:Users/Florian/Documents/Literature/Stock, Watson - 2002 - Macroeconomic Forecasting using Diffusion Indexes(2).pdf:pdf},
issn = {07350015},
journal = {Journal of Business and Economic Statistics},
keywords = {Factor model,Forecasting,Principal components},
number = {2},
pages = {147--162},
title = {{Macroeconomic Forecasting using Diffusion Indexes}},
volume = {20},
year = {2002}
}
@article{Boivin2006a,
abstract = {Factors estimated from large macroeconomic panels are being used in an increasing number of applications. However, little is known about how the size and the composition of the data affect the factor estimates. In this paper, we question whether it is possible to use more series to extract the factors, and yet the resulting factors are less useful for forecasting, and the answer is yes. Such a problem tends to arise when the idiosyncratic errors are cross-correlated. It can also arise if forecasting power is provided by a factor that is dominant in a small dataset but is a dominated factor in a larger dataset. In a real time forecasting exercise, we find that factors extracted from as few as 40 pre-screened series often yield satisfactory or even better results than using all 147 series. Weighting the data by their properties when constructing the factors also lead to improved forecasts. Our simulation analysis is unique in that special attention is paid to cross-correlated idiosyncratic errors, and we also allow the factors to have stronger loadings on some groups of series than others. It thus allows us to better understand the properties of the principal components estimator in empirical applications. ?? 2005 Elsevier B.V. All rights reserved.},
author = {Boivin, Jean and Ng, Serena},
doi = {10.1016/j.jeconom.2005.01.027},
file = {:Users/Florian/Documents/Literature/Boivin, Ng - 2006 - Are more data always better for factor analysis.pdf:pdf},
isbn = {03044076},
issn = {03044076},
journal = {Journal of Econometrics},
keywords = {Factor models,Forecasting,Large N and T,Principal components},
number = {1},
pages = {169--194},
title = {{Are more data always better for factor analysis?}},
volume = {132},
year = {2006}
}
@article{Ghysels2012,
author = {Ghysels, Eric},
file = {:Users/Florian/Documents/Literature/Ghysels - 2012 - Macroeconomics and the Reality of Mixed Frequency Data.pdf:pdf},
journal = {University of North Carolina Working Paper},
pages = {1--52},
title = {{Macroeconomics and the Reality of Mixed Frequency Data}},
year = {2012}
}
@article{Anderson1987,
abstract = {In order to generate a random orthogonal matrix distributed according to Haar measure over the orthogonal group it is natural to start with a matrix of normal random variables and then factor it by the singular value decomposition. A more efficient method is obtained by using Householder transformations. We propose another alternative based on the product of {\$}{\{}{\{}n(n - 1){\}}/2{\}}{\$} orthogonal matrices, each of which represents an angle of rotation. Some numerical comparisons of alternative methods are made.},
author = {Anderson, T. W. and Olkin, I. and Underhill, L. G.},
doi = {10.1137/0908055},
file = {:Users/Florian/Documents/Literature/Anderson, Olkin, Underhill - 1987 - Generation of Random Orthogonal Matrices.pdf:pdf},
issn = {0196-5204},
journal = {SIAM Journal on Scientific and Statistical Computing},
keywords = {haar measure,monte carlo method,orthogonal matrix,random matrix,random number generator,simulation},
number = {2},
pages = {625--629},
title = {{Generation of Random Orthogonal Matrices}},
volume = {8},
year = {1987}
}
@book{Banbura2013a,
abstract = {The term now-casting is a contraction for now and forecasting and has been used for a long time in meteorology and recently also in economics. In this chapter we survey recent developments in economic now-casting with special focus on those models that formalize key features of how market participants and policymakers read macroeconomic data releases in real-time, which involves monitoring many data, forming expectations about them and revising the assessment on the state of the economy whenever realizations diverge sizeably from those expectations. {\textcopyright} 2013 Elsevier B.V.},
author = {Ba{\'{n}}bura, Marta and Giannone, Domenico and Modugno, Michele and Reichlin, Lucrezia},
booktitle = {Handbook of Economic Forecasting},
doi = {10.1016/B978-0-444-53683-9.00004-9},
file = {:Users/Florian/Documents/Literature/Ba{\'{n}}bura et al. - 2013 - Now-casting and the real-time data flow.pdf:pdf},
isbn = {9780444536839},
issn = {15740706},
keywords = {Dynamic factor model,High-dimensional data,Macroeconomic forecasting,Macroeconomic news,Mixed frequency,Real-time data},
pages = {195--237},
title = {{Now-casting and the real-time data flow}},
volume = {2},
year = {2013}
}
@article{Beyeler,
author = {Beyeler, Simon and Kaufmann, Sylvia},
file = {:Users/Florian/Documents/Literature/Beyeler, Kaufmann - Unknown - Factor augmented VAR revisited - A sparse dynamic factor model approach.pdf:pdf},
title = {{Factor augmented VAR revisited - A sparse dynamic factor model approach}}
}
@article{Gneiting2014a,
abstract = {A probabilistic forecast takes the form of a predictive probability distribution over future quantities or events of interest. Probabilistic forecasting aims to maximize the sharpness of the predictive distributions, subject to calibration, on the basis of the available information set. We formalize and study notions of calibration in a prediction space setting. In practice, probabilistic calibration can be checked by examining probability integral transform (PIT) histograms. Proper scoring rules such as the logarithmic score and the continuous ranked probability score serve to assess calibration and sharpness simultaneously. As a special case, consistent scoring functions provide decision-theoretically coherent tools for evaluating point forecasts. We emphasize methodological links to parametric and nonparametric distributional regression techniques, which attempt to model and to estimate conditional distribution functions; we use the context of statistically postprocessed ensemble forecasts in numerical weather prediction as an example. Throughout, we illustrate concepts and methodologies in data examples.},
author = {Gneiting, Tilmann and Katzfuss, Matthias},
doi = {10.1146/annurev-statistics-062713-085831},
file = {:Users/Florian/Documents/Literature/Gneiting, Katzfuss - 2014 - Probabilistic Forecasting.pdf:pdf},
issn = {2326-8298},
journal = {Annual Review of Statistics and Its Application},
keywords = {calibration,consistent scoring function,distributional regression,ensemble forecast,proper scoring,rule},
number = {1},
pages = {125--151},
title = {{Probabilistic Forecasting}},
volume = {1},
year = {2014}
}
@article{Baurle,
author = {B{\"{a}}urle, Gregor and Steiner, Elizabeth},
file = {:Users/Florian/Documents/Literature/B{\"{a}}urle, Steiner - 2013 - How do individual sectors respond to macroeconomic shocks A structural dynamic factor approach applied to Swis.pdf:pdf},
journal = {SNB Working Papers},
keywords = {Sectoral value added,dynamic factor model,sign r},
title = {{How do individual sectors respond to macroeconomic shocks? A structural dynamic factor approach applied to Swiss data}},
year = {2013}
}
@article{Sarferaz2009,
author = {Sarferaz, Samad},
file = {:Users/Florian/Documents/Literature/Sarferaz - 2009 - Essays on Business Cycle Analysis and Demography.pdf:pdf},
title = {{Essays on Business Cycle Analysis and Demography}},
year = {2009}
}
@article{Schorfheide2015,
abstract = {This paper develops a vector autoregression (VAR) for macroeconomic time series which are observed at mixed frequencies – quarterly and monthly. The mixed-frequency VAR is cast in state-space form and estimated with Bayesian methods under a Minnesota-style prior. Using a real-time data set, we generate and evaluate forecasts from the mixed-frequency VAR and compare them to forecasts from a VAR that is estimated based on data time-aggregated to quarterly frequency. We document how information that becomes available within the quarter improves the forecasts in real time.},
author = {Schorfheide, Frank and Song, Dongho},
doi = {10.1080/07350015.2014.954707},
file = {:Users/Florian/Documents/Literature/Schorfheide, Song - 2015 - Real-Time Forecasting with a Mixed-Frequency VAR.pdf:pdf},
isbn = {4144632733},
issn = {0735-0015},
journal = {Journal of Business {\&} Economic Statistics},
keywords = {Bayesian statistical decision theory,Forecasting,Vector autoregression},
number = {April 2017},
pages = {366--380},
title = {{Real-Time Forecasting with a Mixed-Frequency VAR}},
url = {http://ideas.repec.org/p/fip/fedmwp/701.html},
volume = {33},
year = {2015}
}
@article{Ghysels2007,
author = {Ghysels, Eric and Sinko, Arthur and Valkanov, Rossen},
file = {:Users/Florian/Documents/Literature/Ghysels, Sinko, Valkanov - 2007 - MIDAS Regressions Further Results and New Directions.pdf:pdf},
journal = {Econometric Reviews},
number = {1},
pages = {1--48},
title = {{MIDAS Regressions: Further Results and New Directions}},
volume = {26},
year = {2007}
}
@article{Koop2010a,
abstract = {Macroeconomic practitioners frequently work with multivariate time series models such as VARs, factor augmented VARs as well as time- varying parameter versions of these models (including variants with mul- tivariate stochastic volatility). These models have a large number of pa- rameters and, thus, over-parameterization problems may arise. Bayesian methods have become increasingly popular as a way of overcoming these problems. In this monograph, we discuss VARs, factor augmented VARs and time-varying parameter extensions and show how Bayesian inference proceeds. Apart from the simplest of VARs, Bayesian inference requires the use of Markov chain Monte Carlo methods developed for state space models and we describe these algorithms. The focus is on the empiri- cal macroeconomist and we o¤er advice on how to use these models and methods in practice and include empirical illustrations. A website pro- vides Matlab code for carrying out Bayesian inference in these models.},
author = {Koop, Gary and Korobilis, Dimitris},
doi = {10.1561/0800000013},
file = {:Users/Florian/Documents/Literature/Koop, Korobilis - 2010 - Bayesian Multivariate Time Series Methods for Empirical Macroeconomics.pdf:pdf},
isbn = {160198362X},
keywords = {Bayesian estimation,Empirical macroeconometrics,MCMC,factor models,time-varying parameters,vector autoregressions},
number = {20125},
pages = {1--71},
title = {{Bayesian Multivariate Time Series Methods for Empirical Macroeconomics}},
url = {http://mpra.ub.uni-muenchen.de/20125/{\%}5Cnhttp://books.google.com/books?hl=en{\&}lr={\&}id=JcVn9IJ9wSsC{\&}oi=fnd{\&}pg=PA1{\&}dq=Bayesian+Multivariate+Time+Series+Methods+for+Empirical+Macroeconomics{\&}ots=InDMzdUjna{\&}sig=6ZDjx5WsJvNacnUjOQYWJ9EDiOc},
year = {2010}
}
@article{Runstler2009,
abstract = {This paper evaluates different models for the short-term forecasting of real GDP growth in ten selected European countries and the euro area as a whole. Purely quarterly models are compared with models designed to exploit early releases of monthly indicators for the nowcast and forecast of quarterly GDP growth. Amongst the latter, we consider small bridge equations and forecast equations in which the bridging between monthly and quarterly data is achieved through a regression on factors extracted from large monthly datasets. The forecasting exercise is performed in a simulated real-time context, which takes account of publication lags in the individual series. In general, we fi nd that models that exploit monthly information outperform models that use purely quarterly data and, amongst the former, factor models perform best.},
author = {R{\"{u}}nstler, G. and Barhoum, K. and Benk, S. and Cristadoro, R. and Reijer, A. D.E.N. and Jakaitiene, A. and Jelonek, P. and Rua, A. and Ruth, K. and Nieuwenhuyze, C. V.A.N.},
doi = {10.1002/for.1105},
file = {:Users/Florian/Documents/Literature/R{\"{u}}nstler et al. - 2009 - Short-term forecasting of GDP using large datasets A pseudo real-time forecast evaluation exercise.pdf:pdf},
issn = {02776693},
journal = {Journal of Forecasting},
keywords = {Dynamic factor models,State space models,Uoc models},
number = {7},
pages = {595--611},
title = {{Short-term forecasting of GDP using large datasets: A pseudo real-time forecast evaluation exercise}},
volume = {28},
year = {2009}
}
@article{Aruoba2009,
abstract = {We construct a framework for measuring economic activity at high frequency, potentially in real time.We a.scotti@frb use a variety of stock and flow data observed at mixed frequencies (including very high frequencies), and we use a dynamic factor model that permits exact filtering. We illustrate the framework in a prototype empirical example and a simulation study calibrated to the example},
author = {Aruoba, S. Borağan and Diebold, Francis X. and Scotti, Chiara},
doi = {10.1198/jbes.2009.07205},
file = {:Users/Florian/Documents/Literature/Aruoba, Diebold, Scotti - 2009 - Real-Time Measurement of Business Conditions.pdf:pdf},
issn = {0735-0015},
journal = {Journal of Business {\&} Economic Statistics},
keywords = {business cycle,casting,contraction,dynamic factor model,expansion,macroeconomic fore-,recession,state space model,turning point},
number = {4},
pages = {417--427},
title = {{Real-Time Measurement of Business Conditions}},
url = {http://www.tandfonline.com/doi/abs/10.1198/jbes.2009.07205},
volume = {27},
year = {2009}
}
@article{Giannone2008,
abstract = {A formal method is developed for evaluating the marginal impact that intra-monthly data releases have on current-quarter forecasts (nowcasts) of real gross domestic product (GDP) growth. The method can track the real-time flow of the type of information monitored by central banks because it can handle large data sets with staggered data-release dates. Each time new data are released, the nowcasts are updated on the basis of progressively larger data sets that, reflecting the unsynchronized data-release dates, have a "jagged edge" across the most recent months. ?? 2008 Elsevier B.V.},
author = {Giannone, Domenico and Reichlin, Lucrezia and Small, David},
doi = {10.1016/j.jmoneco.2008.05.010},
file = {:Users/Florian/Documents/Literature/Giannone, Reichlin, Small - 2008 - Nowcasting The Real-Time Informational Content of Macroeconomic Data.pdf:pdf},
isbn = {03043932},
issn = {03043932},
journal = {Journal of Monetary Economics},
keywords = {Factor model,Forecasting,Monetary policy,Nowcast,Real-time data},
number = {4},
pages = {665--676},
title = {{Nowcasting: The Real-Time Informational Content of Macroeconomic Data}},
volume = {55},
year = {2008}
}

@Article{ChanLeon-GonzalezStrachan2017,
  author  = {Chan, Joshua and Leon-Gonzalez, Roberto and Strachan, Rodney W.},
  title   = {{Invariant Inference and Efficient Computation in the Static Factor Model}},
  journal = {Journal of the American Statistical Association},
  year    = {2017},
  pages   = {1--27},
  doi     = {10.1080/01621459.2017.1287080},
  file    = {:Users/Florian/Documents/Literature/Chan, Leon-Gonzalez, Strachan - 2017 - Invariant Inference and Efficient Computation in the Static Factor Model.pdf:pdf},
  issn    = {0162-1459},
}
@article{Angelini2011,
abstract = {This paper evaluates models that exploit timely monthly releases to compute early estimates of current quarter GDP (now-casting) in the euro area. We compare traditional methods used at institutions with a new method proposed by Giannone et al. The method consists in bridging quarterly GDP with monthly data via a regression on factors extracted from a large panel of monthly series with different publication lags. We show that bridging via factors produces more accurate estimates than traditional bridge equations. We also show that survey data and other 'soft' information are valuable for now-casting. {\textcopyright} 2011 The Author(s). The Econometrics Journal {\textcopyright} 2011 Royal Economic Society.},
author = {Angelini, Elena and Camba-Mendez, Gonzalo and Giannone, Domenico and Reichlin, Lucrezia and R{\"{u}}nstler, Gerhard},
doi = {10.1111/j.1368-423X.2010.00328.x},
file = {:Users/Florian/Documents/Literature/Angelini et al. - 2011 - Short-term forecasts of euro area GDP growth.pdf:pdf},
issn = {13684221},
journal = {Econometrics Journal},
keywords = {Factor model,Forecasting,Large data sets,Monetary policy,News,Real-time data},
number = {1},
title = {{Short-term forecasts of euro area GDP growth}},
volume = {14},
year = {2011}
}
@article{Primiceri2005,
author = {Primiceri, Giorgio},
file = {:Users/Florian/Documents/Literature/Primiceri - 2005 - Time Varying Structural Vector Autoregressions.pdf:pdf},
journal = {Review of Economic Studies},
keywords = {multivariate stochastic volatility,time varying coefficients},
number = {3},
pages = {821--852},
title = {{Time Varying Structural Vector Autoregressions}},
url = {http://www.yahoo.com/},
volume = {72},
year = {2005}
}
@book{Ghysels2007a,
abstract = {We explore Mixed Data Sampling (henceforth MIDAS) regression models. The regressions involve time series data sampled at different frequencies. Volatility and related processes are our prime focus, though the regression method has wider applications in macroeconomics and finance, among other areas. The regressions combine recent developments regarding estimation of volatility and a not so recent literature on distributed lag models. We study various lag structures to parameterize parsimoniously the regressions and relate them to existing models. We also propose several new extensions of the MIDAS framework. The paper concludes with an empirical section where we provide further evidence and new results on the risk-return tradeoff. We also report empirical evidence on microstructure noise and volatility forecasting.},
author = {Ghysels, Eric and Sinko, Arthur and Valkanov, Rossen},
booktitle = {Econometric Reviews},
doi = {10.1080/07474930600972467},
file = {:Users/Florian/Documents/Literature/Ghysels, Sinko, Valkanov - 2007 - MIDAS regressions Further results and new directions(2).pdf:pdf},
isbn = {0747493060097},
issn = {07474938},
keywords = {Microstructure noise,Nonlinear MIDAS,Risk,Tick-by-tick applications,Volatility},
number = {1},
pages = {53--90},
title = {{MIDAS regressions: Further results and new directions}},
volume = {26},
year = {2007}
}
@article{Paccagnini,
author = {Paccagnini, Alessia},
file = {:Users/Florian/Documents/Literature/Paccagnini - Unknown - Forecasting with FAVAR macroeconomic versus financial factors Forecasting with FAVAR macroeconomic versus finan.pdf:pdf},
number = {256},
title = {{Forecasting with FAVAR : macroeconomic versus financial factors Forecasting with FAVAR : macroeconomic versus financial factors}}
}
@article{McCracken2016a,
abstract = {This paper describes a large, monthly frequency, macroeconomic database with the goal of establishing a convenient starting point for empirical analysis that requires " big data. " The dataset mimics the coverage of those already used in the literature but has three appealing features. First, it is designed to be updated monthly using the FRED database. Second, it will be publicly accessible, facilitating comparison of related research and replication of empirical work. Third, it will relieve researchers from having to manage data changes and revisions. We show that factors extracted from our dataset share the same predictive content as those based on various vintages of the so-called Stock-Watson dataset. In addition, we suggest that diffusion indexes constructed as the partial sum of the factor estimates can potentially be useful for the study of business cycle chronology.},
author = {McCracken, Michael W. and Ng, Serena},
doi = {10.1080/07350015.2015.1086655},
file = {:Users/Florian/Documents/Literature/McCracken, Ng - 2016 - FRED-MD A Monthly Database for Macroeconomic Research.pdf:pdf},
issn = {15372707},
journal = {Journal of Business and Economic Statistics},
keywords = {Big data,Diffusion index,Factors,Forecasting},
number = {4},
pages = {574--589},
title = {{FRED-MD: A Monthly Database for Macroeconomic Research}},
volume = {34},
year = {2016}
}
@article{Mariano2003,
author = {Mariano, Roberto S. and Murasawa, Yasutomo},
doi = {10.1002/jae.695},
file = {:Users/Florian/Documents/Literature/Mariano, Murasawa - 2003 - A New Coincident Index of Business Cycles Based on Monthly and Quarterly Series.pdf:pdf},
journal = {Journal of Applied Econometrics},
number = {18},
pages = {427--443},
title = {{A New Coincident Index of Business Cycles Based on Monthly and Quarterly Series}},
volume = {2004},
year = {2003}
}
@article{Clark2011,
abstract = {Central banks and other forecasters are increasingly interested in various aspects of density forecasts. However, recent sharp changes in macroeconomic volatility, including the Great Moderation and the more recent sharp rise in volatility associated with increased variation in energy prices and the deep global recession?pose significant challenges to density forecasting. Accordingly, this paper examines, with real-time data, density forecasts of U.S. GDP growth, unemployment, inflation, and the federal funds rate from Bayesian vector autoregression (BVAR) models with stochastic volatility. The results indicate that adding stochastic volatility to BVARs materially improves the real-time accuracy of density forecasts. This article has supplementary material online.$\backslash$nCentral banks and other forecasters are increasingly interested in various aspects of density forecasts. However, recent sharp changes in macroeconomic volatility, including the Great Moderation and the more recent sharp rise in volatility associated with increased variation in energy prices and the deep global recession?pose significant challenges to density forecasting. Accordingly, this paper examines, with real-time data, density forecasts of U.S. GDP growth, unemployment, inflation, and the federal funds rate from Bayesian vector autoregression (BVAR) models with stochastic volatility. The results indicate that adding stochastic volatility to BVARs materially improves the real-time accuracy of density forecasts. This article has supplementary material online.},
author = {Clark, Todd E.},
doi = {10.1198/jbes.2010.09248},
file = {:Users/Florian/Documents/Literature/Clark - 2011 - Real-Time Density Forecasts From Bayesian Vector Autoregressions With Stochastic Volatility.pdf:pdf},
issn = {0735-0015},
journal = {Journal of Business {\&} Economic Statistics},
keywords = {bayesian methods,steady-state prior},
number = {3},
pages = {327--341},
title = {{Real-Time Density Forecasts From Bayesian Vector Autoregressions With Stochastic Volatility}},
volume = {29},
year = {2011}
}
@article{Armesto2010,
author = {Armesto, Michelle T. and Engemann, Kristie M. and Owyang, Michael T.},
file = {:Users/Florian/Documents/Literature/Armesto, Engemann, Owyang - 2010 - Forecasting with Mixed Frequencies.pdf:pdf},
journal = {Federal Reserve Bank of St. Louis Review},
keywords = {C32,Federal Reserve Bank of St. Louis,Kristie Engemann,Michael Mike Owyang,Michelle Armesto,economic research},
number = {6},
pages = {521--536},
title = {{Forecasting with Mixed Frequencies}},
volume = {92},
year = {2010}
}
@article{Banbura2011,
abstract = {We derive forecast weights and uncertainty measures for assessing the roles of individual series in a dynamic factor model (DFM) for forecasting the euro area GDP from monthly indicators. The use of the Kalman smoother allows us to deal with publication lags when calculating the above measures. We find that surveys and financial data contain important information for the GDP forecasts beyond the monthly real activity measures. However, this is discovered only if their more timely publication is taken into account properly. Differences in publication lags play a very important role and should be considered in forecast evaluation. {\textcopyright} 2010 International Institute of Forecasters.},
author = {Ba{\'{n}}bura, Marta and R{\"{u}}nstler, Gerhard},
doi = {10.1016/j.ijforecast.2010.01.011},
file = {:Users/Florian/Documents/Literature/Ba{\'{n}}bura, R{\"{u}}nstler - 2011 - A look into the factor model black box Publication lags and the role of hard and soft data in forecasting G.pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {Dynamic factor models,Filter weights,GDP,Publication lags},
number = {2},
pages = {333--346},
title = {{A look into the factor model black box: Publication lags and the role of hard and soft data in forecasting GDP}},
volume = {27},
year = {2011}
}
@article{Schumacher2016,
abstract = {This paper compares two single-equation approaches from the recent nowcasting literature: mixed-data sampling (MIDAS) regressions and bridge equations. Both approaches are suitable for nowcasting low-frequency variables such as the quarterly GDP using higher-frequency business cycle indicators. Three differences between the approaches are identified: (1) MIDAS is a direct multi-step nowcasting tool, whereas bridge equations provide iterated forecasts; (2) the weighting of high-frequency predictor observations in MIDAS is based on functional lag polynomials, whereas the bridge equation weights are fixed partly by time aggregation; (3) for parameter estimation, the MIDAS equations consider current-quarter leads of high-frequency indicators, whereas bridge equations typically do not. To assist in discussing the differences between the approaches in isolation, intermediate specifications between MIDAS and bridge equations are provided. The alternative models are compared in an empirical application to nowcasting GDP growth in the Euro area, given a large set of business cycle indicators.},
author = {Schumacher, Christian},
doi = {10.1016/j.ijforecast.2015.07.004},
file = {:Users/Florian/Documents/Literature/Schumacher - 2016 - A comparison of MIDAS and bridge equations.pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {Bridge equations,Mixed-data sampling,Nowcasting},
number = {2},
pages = {257--270},
publisher = {Elsevier B.V.},
title = {{A comparison of MIDAS and bridge equations}},
url = {http://dx.doi.org/10.1016/j.ijforecast.2015.07.004},
volume = {32},
year = {2016}
}
@article{Evans2005,
abstract = {This paper describes a method for calculating daily real- time estimates of the current state of the U.S. economy. The estimates are computed from data on scheduled U.S. macro- economic announcements using an econometric model that al- lows for variable reporting lags, temporal aggregation, and other complications in the data. The model can be applied to find real-time estimates of GDP, inflation, unemployment, or any other macroeconomic variable of interest. In this paper, I focus on the problem of estimating the current level of and growth rate in GDP. I construct daily real-time estimates of GDP that incorporate public information known on the day in question. The real-time estimates produced by the model are uniquely suited to studying how perceived developments in the macroeconomy are linked to asset prices over a wide range of frequencies. The estimates also provide, for the first time, daily time series that can be used in practical policy decisions.},
author = {Evans, Martin D.},
doi = {10.2139/ssrn.646103},
file = {:Users/Florian/Documents/Literature/Evans - 2005 - Where Are We Now Real-Time Estimates of the Macroeconomy.pdf:pdf},
issn = {1556-5068},
journal = {International Journal of Central Banking},
pages = {127--175},
title = {{Where Are We Now? Real-Time Estimates of the Macroeconomy}},
year = {2005}
}
@article{Aguilar2000,
author = {Aguilar, Omar and West, Mike},
file = {:Users/Florian/Documents/Literature/Aguilar, West - 2000 - Bayesian dynamic factor models and variance matrix discounting for portfolio allocation.pdf:pdf},
journal = {J. Bus. Econom. Statist.},
keywords = {dynamic factor analysis,dynamic linear models,exchange rates forecasting,markov chain monte carlo,multivariate stochastic volatility,portfolio selection,variance},
number = {January},
pages = {338--357},
title = {{Bayesian dynamic factor models and variance matrix discounting for portfolio allocation}},
volume = {18},
year = {2000}
}
@article{Ghysels2004,
author = {Ghysels, Eric and Santa-Clara, Pedro and Valkanov, Rossen},
file = {:Users/Florian/Documents/Literature/Ghysels, Santa-Clara, Valkanov - 2004 - The MIDAS Touch Mixed Data Sampling Regression Models.pdf:pdf},
journal = {CIRANO Working Papers},
pages = {1--33},
title = {{The MIDAS Touch: Mixed Data Sampling Regression Models}},
volume = {20},
year = {2004}
}
@article{Doz2011,
abstract = {This paper shows consistency of a two-step estimation of the factors in a dynamic approximate factor model when the panel of time series is large (n large). In the first step, the parameters of the model are estimated from an OLS on principal components. In the second step, the factors are estimated via the Kalman smoother. The analysis develops the theory for the estimator considered in Giannone et al. (2004) and Giannone et al. (2008) and for the many empirical papers using this framework for nowcasting. ?? 2011 Elsevier B.V. All rights reserved.},
author = {Doz, Catherine and Giannone, Domenico and Reichlin, Lucrezia},
doi = {10.1016/j.jeconom.2011.02.012},
file = {:Users/Florian/Documents/Literature/Doz, Giannone, Reichlin - 2011 - A two-step estimator for large approximate dynamic factor models based on Kalman filtering.pdf:pdf},
isbn = {03044076},
issn = {03044076},
journal = {Journal of Econometrics},
keywords = {Factor models,Kalman filter,Large cross-sections,Principal components},
number = {1},
pages = {188--205},
pmid = {1262605},
publisher = {Elsevier B.V.},
title = {{A two-step estimator for large approximate dynamic factor models based on Kalman filtering}},
url = {http://dx.doi.org/10.1016/j.jeconom.2011.02.012},
volume = {164},
year = {2011}
}
@article{Assmann2016,
abstract = {Due to their indeterminacies, static and dynamic factor models require identifying assumptions to guarantee uniqueness of the parameter estimator. The indeterminacy of the parameter estimator with respect to an orthogonal transformation is known as the rotation problem. The typical strategy in Bayesian factor analysis to solve the rotation problem is to introduce ex-ante constraints on certain model parameters via degenerate and truncated prior distributions. This strategy, however, results in posterior distributions whose shapes depend on the ordering of the variables in the data set. We propose an alternative approach where the rotation problem is solved ex-post using Procrustean postprocessing. The resulting order invariance of the posterior estimator is illustrated in a simulation study and an empirical application using an established data set containing 120 macroeconomic time series. Favorable properties of the ex-post approach with respect to convergence, statistical and numerical accuracy are revealed.},
author = {A{\ss}mann, Christian and Boysen-Hogrefe, Jens and Pape, Markus},
doi = {10.1016/j.jeconom.2015.10.010},
file = {:Users/Florian/Documents/Literature/A{\ss}mann, Boysen-Hogrefe, Pape - 2016 - Bayesian Analysis of Static and Dynamic Factor Models An Ex-Post Approach Towards the Rotation Pr.pdf:pdf},
issn = {18726895},
journal = {Journal of Econometrics},
keywords = {Bayesian estimation,Factor models,Multimodality,Ordering problem,Orthogonal transformation,Rotation problem},
number = {1},
pages = {190--206},
publisher = {Elsevier B.V.},
title = {{Bayesian Analysis of Static and Dynamic Factor Models: An Ex-Post Approach Towards the Rotation Problem}},
url = {http://dx.doi.org/10.1016/j.jeconom.2015.10.010},
volume = {192},
year = {2016}
}
@article{Cesur2016,
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Amisano, Gianni and Geweke, John},
doi = {10.1162/REST},
eprint = {arXiv:1011.1669v3},
file = {:Users/Florian/Documents/Literature/Amisano, Geweke - 2017 - Prediction Using Several Macroeconomic Models.pdf:pdf},
isbn = {1000142405274},
issn = {1725-2806},
journal = {Review of Economics and Statistics},
keywords = {Economic Fluctuations and Growth,Monetary Economics,Technical Working Papers},
number = {5},
pages = {912--925},
pmid = {21860536},
title = {{Prediction Using Several Macroeconomic Models}},
volume = {99},
year = {2017}
}
@article{Stock20011,
author = {Stock, James H. and Watson, Mark W.},
file = {:Users/Florian/Documents/Literature/Stock, Watson - 2011 - Dynamic Factor Models.pdf:pdf},
isbn = {9780195398649},
journal = {Oxford Handbook of Economic Forecasting},
number = {July},
pages = {1--43},
title = {{Dynamic Factor Models}},
url = {http://link.springer.com/article/10.1007/s10182-006-0219-z},
year = {2011}
}
@article{Stock2002a,
abstract = {This article studies forecasting a macroeconomic time series variable using a large number of predictors. The predictors are summarized using a small number of indexes constructed by principal component analysis. An approximate dynamic factor model serves as the statistical framework for the estimation of the indexes and construction of the forecasts. The method is used to construct 6-, 12-, and 24-monthahead forecasts for eight monthly U.S. macroeconomic time series using 215 predictors in simulated real time from 1970 through 1998. During this sample period these new forecasts outperformed univariate autoregressions, small vector autoregressions, and leading indicator models.},
author = {Stock, James H and Watson, Mark W},
doi = {10.1198/073500102317351921},
file = {:Users/Florian/Documents/Literature/Stock, Watson - 2002 - Macroeconomic Forecasting Using Diffusion Indexes.pdf:pdf},
isbn = {07350015},
issn = {0735-0015},
journal = {Journal of Business {\&} Economic Statistics},
keywords = {Factor model,Forecasting,Principal components},
number = {2},
pages = {147--162},
title = {{Macroeconomic Forecasting Using Diffusion Indexes}},
url = {http://www.tandfonline.com/doi/abs/10.1198/073500102317351921},
volume = {20},
year = {2002}
}
@article{Beauchemin2013,
author = {Beauchemin, Kenneth},
file = {:Users/Florian/Documents/Literature/Beauchemin - 2013 - A 14-Variable Mixed-Frequency VAR Model.pdf:pdf},
keywords = {bayesian vector autoregression,c11,c32,c53,forecasting,jel classi fi cation},
number = {December},
title = {{A 14-Variable Mixed-Frequency VAR Model}},
year = {2013}
}
@article{Forni2016,
author = {Forni, Mario and Giovannelli, Alessandro and Lippi, Marco and Soccorsi, Stefano},
file = {:Users/Florian/Documents/Literature/Forni et al. - 2016 - Dynamic Factor Model with Infinite Dimensional Factor Space Forecasting.pdf:pdf},
number = {March},
title = {{Dynamic Factor Model with Infinite Dimensional Factor Space: Forecasting}},
year = {2016}
}
@article{Barnett2014,
abstract = {Evidence from a large and growing body of empirical literature strongly suggests that there have been changes in the inflation and output dynamics in the United Kingdom. The majority of these papers base their results on a class of econometric models that allows for time-variation in the coefficients and volatilities of shocks. While these models have been used extensively for studying evolving dynamics and for structural analysis, there has been little evidence that they are useful for forecasting UK output growth and inflation. This paper attempts to fill this gap by comparing the performances of a wide range of time-varying parameter models in forecasting output growth and inflation. We find that allowing for time-varying parameters can lead to large and statistically significant gains in forecast accuracy. {\textcopyright} 2013 The Bank of England.},
author = {Barnett, Alina and Mumtaz, Haroon and Theodoridis, Konstantinos},
doi = {10.1016/j.ijforecast.2013.06.002},
file = {:Users/Florian/Documents/Literature/Barnett, Mumtaz, Theodoridis - 2014 - Forecasting UK GDP growth and inflation under structural change. A comparison of models with time-.pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {Forecast comparison,Regime switching,Time-varying parameters,Vector autoregressions},
number = {1},
pages = {12--143},
publisher = {Elsevier B.V.},
title = {{Forecasting UK GDP growth and inflation under structural change. A comparison of models with time-varying parameters}},
url = {http://dx.doi.org/10.1016/j.ijforecast.2013.06.002},
volume = {30},
year = {2014}
}
@book{Stock2016,
abstract = {This chapter provides an overview of and user's guide to dynamic factor models (DFMs), their estimation, and their uses in empirical macroeconomics. It also surveys recent developments in methods for identifying and estimating SVARs, an area that has seen important developments over the past 15 years. The chapter begins by introducing DFMs and the associated statistical tools, both parametric (state-space forms) and nonparametric (principal components and related methods). After reviewing two mature applications of DFMs, forecasting and macroeconomic monitoring, the chapter lays out the use of DFMs for analysis of structural shocks, a special case of which is factor-augmented vector autoregressions (FAVARs). A main focus of the chapter is how to extend methods for identifying shocks in structural vector autoregression (SVAR) to structural DFMs. The chapter provides a unification of SVARs, FAVARs, and structural DFMs and shows both in theory and through an empirical application to oil shocks how the same identification strategies can be applied to each type of model.},
author = {Stock, J. H. and Watson, M. W.},
booktitle = {Handbook of Macroeconomics},
doi = {10.1016/bs.hesmac.2016.04.002},
edition = {1},
file = {:Users/Florian/Documents/Literature/Stock, Watson - 2016 - Dynamic Factor Models, Factor-Augmented Vector Autoregressions, and Structural Vector Autoregressions in Macroeco.pdf:pdf},
isbn = {9780444594877},
issn = {15740048},
keywords = {Factor-augmented vector autoregressions,Large-model forecasting,Nowcasting,Principal components,State-space models,Structural shocks,Structural vector autoregressions},
pages = {415--525},
publisher = {Elsevier B.V.},
title = {{Dynamic Factor Models, Factor-Augmented Vector Autoregressions, and Structural Vector Autoregressions in Macroeconomics}},
url = {http://dx.doi.org/10.1016/bs.hesmac.2016.04.002},
volume = {2},
year = {2016}
}
@book{Kim1999a,
author = {Kim, Chang-Jin and Nelson, Charles R.},
booktitle = {MIT Press Books},
doi = {10.2307/2669796},
file = {:Users/Florian/Documents/Literature/Kim, Nelson - 1999 - State-Space Models with Regime-Switching Classical and Gibbs Sampling Approaches with Applications(2).pdf:pdf},
isbn = {9780262112383},
issn = {01621459},
pages = {1--297},
publisher = {The MIT press},
title = {{State-Space Models with Regime-Switching: Classical and Gibbs Sampling Approaches with Applications}},
url = {http://proxy.mul.missouri.edu/login?url=http://search.ebscohost.com/login.aspx?direct=true{\&}db=e000xna{\&}AN=9231{\&}site=ehost-live{\&}scope=site},
year = {1999}
}
@article{Polson2010,
abstract = {We study the classic problem of choosing a prior distribution for a location parameter $\beta$ = ($\beta$1, . . . ,$\beta$p) as p grows large. First, we study the stan- dard “global-local shrinkage” approach, based on scale mixtures of normals. Two theorems are presented which characterize certain desirable properties of shrinkage priors for sparse problems. Next, we review some recent results showing how L´ evy processes can be used to generate infinite-dimensional ver- sions of standard normal scale-mixture priors, along with new priors that have yet to be seriously studied in the literature. This approach provides an intuitive framework both for generating new regularization penalties and shrinkage rules, and for performing asymptotic analysis on existing models.},
author = {Polson, Nicholas G. and Scott, James G.},
doi = {10.1093/acprof:oso/9780199694587.003.0017},
file = {:Users/Florian/Documents/Literature/Polson, Scott - 2010 - Shrink Globally, Act Locally Sparse Bayesian Regularization and Prediction.pdf:pdf},
isbn = {9780191731921},
journal = {Bayesian Statistics},
keywords = {L{\'{e}}vy processes,Shrinkage,Sparsity},
title = {{Shrink Globally, Act Locally: Sparse Bayesian Regularization and Prediction}},
volume = {9},
year = {2010}
}
@article{Stock2006,
abstract = {Historically, time series forecasts of economic variables have used only a handful of predictor variables, while forecasts based on a large number of predictors have been the province of judgmental forecasts and large structural econometric models. The past decade, however, has seen considerable progress in the development of time series forecasting methods that exploit many predictors, and this chapter surveys these methods. The first group of methods considered is forecast combination (forecast pooling), in which a single forecast is produced from a panel of many forecasts. The second group of methods is based on dynamic factor models, in which the comovements among a large number of economic variables are treated as arising from a small number of unobserved sources, or factors. In a dynamic factor model, estimates of the factors (which become increasingly precise as the number of series increases) can be used to forecast individual economic variables. The third group of methods is Bayesian model averaging, in which the forecasts from very many models, which differ in their constituent variables, are averaged based on the posterior probability assigned to each model. The chapter also discusses empirical Bayes methods, in which the hyperparameters of the priors are estimated. An empirical illustration applies these different methods to the problem of forecasting the growth rate of the U.S. index of industrial production with 130 predictor variables. ?? 2006 Elsevier B.V. All rights reserved.},
author = {Stock, James H. and Watson, Mark W.},
doi = {10.1016/S1574-0706(05)01010-4},
file = {:Users/Florian/Documents/Literature/Stock, Watson - 2006 - Forecasting with Many Predictors.pdf:pdf},
isbn = {9780444513953},
issn = {15740706},
journal = {Handbook of Economic Forecasting},
keywords = {Bayesian model averaging,dynamic factor models,empirical Bayes forecasts,forecast combining,principal components analysis,shrinkage forecasts},
number = {05},
pages = {515--554},
title = {{Forecasting with Many Predictors}},
volume = {1},
year = {2006}
}
@article{Chan2009,
abstract = {We consider the problem of implementing simple and efficient Markov chain Monte Carlo (MCMC) estimation algorithms for state space models. A conceptually transparent derivation of the posterior distribution of the states is discussed, which also leads to an efficient simulation algorithm that is modular, scalable and widely applicable. We also discuss a simple approach for evaluating the integrated likelihood, defined as the density of the data given the parameters but marginal of the state vector. We show that this high-dimensional integral can be easily evaluated with minimal computational and conceptual difficulty. Two empirical applications in macroeconomics demonstrate that the methods are versatile and computationally undemanding. In one application, involving a time-varying parameter model, we show that the methods allow for efficient handling of large state vectors. In our second application, involving a dynamic factor model, we introduce a new blocking strategy which results in improved MCMC mixing at little cost. The results demonstrate that the framework is simple, flexible and efficient.},
author = {Chan, J.C.C. and Jeliazkov, I.},
doi = {10.1504/IJMMNO.2009.030090},
file = {:Users/Florian/Documents/Literature/Chan, Jeliazkov - 2009 - Efficient Simulation and Integrated Likelihood Estimation in State Space Models.pdf:pdf},
issn = {2040-3607},
journal = {International Journal of Mathematical Modelling and Numerical Optimisation},
keywords = {Banded matrix,Bayesian estimation,Collapsed sampler,Dynamic factor model,Kalman filter,MCMC,Markov chain Monte Carlo,State smoothing,Time-varying parameter model},
number = {1-2},
pages = {101--120},
title = {{Efficient Simulation and Integrated Likelihood Estimation in State Space Models}},
volume = {1},
year = {2009}
}
@article{Foroni2014,
abstract = {In this paper, we focus on the different methods which have been proposed in the literature to date for dealing with mixed-frequency and ragged-edge datasets: bridge equations, mixed-data sampling (MIDAS), and mixed-frequency VAR (MF-VAR) models. We discuss their performances for nowcasting the quarterly growth rate of the Euro area GDP and its components, using a very large set of monthly indicators. We investigate the behaviors of single indicator models, forecast combinations and factor models, in a pseudo real-time framework. MIDAS with an AR component performs quite well, and outperforms MF-VAR at most horizons. Bridge equations perform well overall. Forecast pooling is superior to most of the single indicator models overall. Pooling information using factor models gives even better results. The best results are obtained for the components for which more economically related monthly indicators are available. Nowcasts of GDP components can then be combined to obtain nowcasts for the total GDP growth. {\textcopyright} 2013 International Institute of Forecasters.},
author = {Foroni, Claudia and Marcellino, Massimiliano},
doi = {10.1016/j.ijforecast.2013.01.010},
file = {:Users/Florian/Documents/Literature/Foroni, Marcellino - 2014 - A comparison of mixed frequency approaches for nowcasting Euro area macroeconomic aggregates.pdf:pdf},
isbn = {0169-2070},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {Bridge models,Factor models,MIDAS,Mixed-frequency VAR,Mixed-frequency data,Nowcasting},
number = {3},
pages = {554--568},
publisher = {Elsevier B.V.},
title = {{A comparison of mixed frequency approaches for nowcasting Euro area macroeconomic aggregates}},
url = {http://dx.doi.org/10.1016/j.ijforecast.2013.01.010},
volume = {30},
year = {2014}
}
@article{Bai2008,
author = {Bai, Jushan and Wang, Peter},
file = {:Users/Florian/Documents/Literature/Bai, Wang - 2008 - Identification and Estimation of Dynamic Factor Models.pdf:pdf},
journal = {Business},
number = {8225},
title = {{Identification and Estimation of Dynamic Factor Models}},
year = {2008}
}
@misc{Geweke1996,
abstract = {This article provides an exact Bayesian framework for analyzing the arbitrage pricing theory (APT). Based on the Gibbs sampler, we show how to obtain the exact posterior distributions for functions of interest in the factor model. In particular, we propose a measure of the APT pricing deviations and obtain its exact posterior distribution. Using monthly portfolio returns grouped by industry and market capitalization, we find that there is little improvement in reducing the pricing errors by including more factors beyond the first one.},
author = {Geweke, John and Zhou, Guofu},
booktitle = {Review of Financial Studies},
doi = {10.1093/rfs/9.2.557},
file = {:Users/Florian/Documents/Literature/Geweke, Zhou - 1996 - Measuring the Pricing Error of the Arbitrage Pricing Theory.pdf:pdf},
isbn = {0893-9454},
issn = {14657368},
number = {2},
pages = {557--587},
title = {{Measuring the Pricing Error of the Arbitrage Pricing Theory}},
url = {http://rfs.oupjournals.org/cgi/doi/10.1093/rfs/9.2.557},
volume = {9},
year = {1996}
}
@article{Boero2011,
abstract = {This article provides a practical evaluation of some leading density forecast scoring rules in the context of forecast surveys. We analyse the density forecasts of UK inflation obtained from the Bank of England's Survey of External Forecasters, considering both the survey average forecasts published in the Bank's quarterly Inflation Report, and the individual survey responses recently made available to researchers by the Bank. The density forecasts are collected in histogram format, and the ranked probability score (RPS) is shown to have clear advantages over other scoring rules. Missing observations are a feature of forecast surveys, and we introduce an adjustment to the RPS, based on the Yates decomposition, to improve its comparative measurement of forecaster performance in the face of differential non-response. The new measure, denoted RPS*, is recommended to analysts of forecast surveys. {\textcopyright} 2010 International Institute of Forecasters.},
author = {Boero, Gianna and Smith, Jeremy and Wallis, Kenneth F.},
doi = {10.1016/j.ijforecast.2010.04.003},
file = {:Users/Florian/Documents/Literature/Boero, Smith, Wallis - 2011 - Scoring rules and survey density forecasts.pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {Bank of England Survey of External Forecasters,Brier (quadratic probability) score,Density forecast evaluation,Epstein (ranked probability) score,Forecast comparison,Logarithmic score,Missing data},
number = {2},
pages = {379--393},
title = {{Scoring rules and survey density forecasts}},
volume = {27},
year = {2011}
}
@article{Sarferaz2016,
abstract = {Recent studies using long-run restrictions question the valid- ity of the technology-driven real business cycle hypothesis. We propose an alternative identification that maximizes the contribution of technology shockstotheforecast-errorvarianceoflaborproductivityatalongbutfinite horizon. In small-sample Monte Carlo experiments, our identification out- performs standard long-run restrictions by significantly reducing the bias in the short-run impulse responses and raising their estimation precision. Unlike its long-run restriction counterpart, when our Max Share identifica- tion technique is applied to U.S. data, it delivers the robust result that hours worked responds negatively to positive technology shocks.},
author = {Ritschl, Albrecht and Sarferaz, Samad and Uebele, Martin},
doi = {10.1162/REST},
file = {:Users/Florian/Documents/Literature/Ritschl, Sarferaz, Uebele - 2016 - The U.S. Business Cycle, 1867–2006 A Dynamic Factor Approach.pdf:pdf},
isbn = {1000142405274},
issn = {1725-2806},
journal = {Review of Economics and Statistics},
keywords = {Economic Fluctuations and Growth,Monetary Economics,Technical Working Papers},
number = {1},
pages = {159--172},
pmid = {21860536},
title = {{The U.S. Business Cycle, 1867–2006: A Dynamic Factor Approach}},
volume = {98},
year = {2016}
}
@article{Carriero2015,
abstract = {This paper develops a method for producing current-quarter forecasts of GDP growth with a (possibly large) range of available within-the-quarter monthly observations of economic indicators, such as employment and industrial production, and financial indicators, such as stock prices and interest rates. In light of existing evidence of time variation in the variances of shocks to GDP, we consider versions of the model with both constant variances and stochastic volatility. We also evaluate models with either constant or time-varying regression coefficients. We use Bayesian methods to estimate the model, in order to facilitate providing shrinkage on the (possibly large) set of model parameters and conveniently generate predictive densities. We provide results on the accuracy of nowcasts of real-time GDP growth in the U.S. from 1985 through 2011. In terms of point forecasts, our proposal is comparable to alternative econometric methods and survey forecasts. In addition, it provides reliable density forecasts, for which the stochastic volatility specification is quite useful, while parameter time-variation does not seem to matter.},
author = {Carriero, Andrea and Clark, Todd E. and Marcellino, Massimiliano},
doi = {10.1111/rssa.12092},
file = {:Users/Florian/Documents/Literature/Carriero, Clark, Marcellino - 2015 - Realtime nowcasting with a Bayesian mixed frequency model with stochastic volatility.pdf:pdf},
issn = {1467985X},
journal = {Journal of the Royal Statistical Society. Series A: Statistics in Society},
keywords = {Bayesian methods,Forecasting,Mixed frequency models,Prediction},
number = {4},
pages = {837--862},
title = {{Realtime nowcasting with a Bayesian mixed frequency model with stochastic volatility}},
volume = {178},
year = {2015}
}
@article{Primiceri2014,
author = {Primiceri, Giorgio},
file = {:Users/Florian/Documents/Literature/Primiceri - 2014 - Time-Varying Structural Vector Autoregressions and Monetary Policy A Corrigendum.pdf:pdf},
number = {October},
title = {{Time-Varying Structural Vector Autoregressions and Monetary Policy: A Corrigendum}},
year = {2014}
}

@Article{CarterKohn1994,
  author    = {C. K. Carter and R. Kohn},
  title     = {On Gibbs Sampling for State Space Models},
  journal   = {Biometrika},
  year      = {1994},
  volume    = {81},
  number    = {3},
  pages     = {541--553},
  abstract  = {We show how to use the Gibbs sampler to carry out Bayesian inference on a linear state space model with errors that are a mixture of normals and coefficients that can switch over time. Our approach simultaneously generates the whole of the state vector given the mixture and coefficient indicator variables and simultaneously generates all the indicator variables conditional on the state vectors. The states are generated efficiently using the Kalman filter. We illustrate our approach by several examples and empirically compare its performance to another Gibbs sampler where the states are generated one at a time. The empirical results suggest that our approach is both practical to implement and dominates the Gibbs sampler that generates the states one at a time.},
  issn      = {00063444},
  publisher = {[Oxford University Press, Biometrika Trust]},
  url       = {http://www.jstor.org/stable/2337125},
}

@Article{Fruehwirth-Schnatter1994,
  author   = {Frühwirth-Schnatter, Sylvia},
  title    = {Data Augmentation and Dynamic Linear Models},
  journal  = {Journal of Time Series Analysis},
  year     = {1994},
  volume   = {15},
  number   = {2},
  pages    = {183-202},
  abstract = {Abstract. We define a subclass of dynamic linear models with unknown hyperpara-meter called d-inverse-gamma models. We then approximate the marginal probability density functions of the hyperparameter and the state vector by the data augmentation algorithm of Tanner and Wong. We prove that the regularity conditions for convergence hold. For practical implementation a forward-filtering-backward-sampling algorithm is suggested, and the relation to Gibbs sampling is discussed in detail.},
  doi      = {10.1111/j.1467-9892.1994.tb00184.x},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-9892.1994.tb00184.x},
  keywords = {Approximate Bayesian analysis, data augmentation, dynamic linear models, Gibbs sampling, Kalman filtering, state space models},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9892.1994.tb00184.x},
}

@Article{hamilton1994time,
  author  = {Hamilton, James},
  title   = {Time series econometrics},
  journal = {Princeton U. Press, Princeton},
  year    = {1994},
}

@Book{harvey1990forecasting,
  title     = {Forecasting, structural time series models and the Kalman filter},
  publisher = {Cambridge university press},
  year      = {1990},
  author    = {Harvey, Andrew C},
}

@Article{McCauslandetal2011,
  author   = {McCausland, William and Miller, Shirley and Pelletier, Denis},
  title    = {Simulation smoothing for state-space models: A computational efficiency analysis},
  journal  = {Computational Statistics \& Data Analysis},
  year     = {2011},
  volume   = {55},
  number   = {1},
  pages    = {199-212},
  abstract = {Simulation smoothing involves drawing state variables (or innovations) in discrete time state-space models from their conditional distribution given parameters and observations. Gaussian simulation smoothing is of particular interest, not only for the direct analysis of Gaussian linear models, but also for the indirect analysis of more general models. Several methods for Gaussian simulation smoothing exist, most of which are based on the Kalman filter. Since states in Gaussian linear state-space models are Gaussian Markov random fields, it is also possible to apply the Cholesky Factor Algorithm (CFA) to draw states. This algorithm takes advantage of the band diagonal structure of the Hessian matrix of the log density to make efficient draws. We show how to exploit the special structure of state-space models to draw latent states even more efficiently. We analyse the computational efficiency of Kalman-filter-based methods, the CFA, and our new method using counts of operations and computational experiments. We show that for many important cases, our method is most efficient. Gains are particularly large for cases where the dimension of observed variables is large or where one makes repeated draws of states for the same parameter values. We apply our method to a multivariate Poisson model with time-varying intensities, which we use to analyse financial market transaction count data.},
  keywords = {State-space models Markov chain Monte Carlo Importance sampling Count data High frequency financial data},
  url      = {https://EconPapers.repec.org/RePEc:eee:csdana:v:55:y:2011:i:1:p:199-212},
}

@Article{KastnerFruehwirth-Schnatter2014,
  author   = {Gregor Kastner and Sylvia Frühwirth-Schnatter},
  title    = {Ancillarity-sufficiency interweaving strategy (ASIS) for boosting MCMC estimation of stochastic volatility models},
  journal  = {Computational Statistics \& Data Analysis},
  year     = {2014},
  volume   = {76},
  pages    = {408 - 423},
  note     = {CFEnetwork: The Annals of Computational and Financial Econometrics},
  abstract = {Bayesian inference for stochastic volatility models using MCMC methods highly depends on actual parameter values in terms of sampling efficiency. While draws from the posterior utilizing the standard centered parameterization break down when the volatility of volatility parameter in the latent state equation is small, non-centered versions of the model show deficiencies for highly persistent latent variable series. The novel approach of ancillarity-sufficiency interweaving has recently been shown to aid in overcoming these issues for a broad class of multilevel models. It is demonstrated how such an interweaving strategy can be applied to stochastic volatility models in order to greatly improve sampling efficiency for all parameters and throughout the entire parameter range. Moreover, this method of “combining best of different worlds” allows for inference for parameter constellations that have previously been infeasible to estimate without the need to select a particular parameterization beforehand.},
  doi      = {https://doi.org/10.1016/j.csda.2013.01.002},
  issn     = {0167-9473},
  keywords = {Markov chain Monte Carlo, Non-centering, Auxiliary mixture sampling, Massively parallel computing, State space model, Exchange rate data},
  url      = {http://www.sciencedirect.com/science/article/pii/S0167947313000030},
}

@Article{AhnHorenstein2013,
  author   = {Ahn, Seung C. and Horenstein, Alex R.},
  title    = {Eigenvalue Ratio Test for the Number of Factors},
  journal  = {Econometrica},
  year     = {2013},
  volume   = {81},
  number   = {3},
  pages    = {1203-1227},
  abstract = {This paper proposes two new estimators for determining the number of factors (r) in static approximate factor models. We exploit the well-known fact that the r largest eigenvalues of the variance matrix of N response variables grow unboundedly as N increases, while the other eigenvalues remain bounded. The new estimators are obtained simply by maximizing the ratio of two adjacent eigenvalues. Our simulation results provide promising evidence for the two estimators.},
  doi      = {10.3982/ECTA8968},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.3982/ECTA8968},
  keywords = {Approximate factor models, number of factors, eigenvalues},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.3982/ECTA8968},
}

@Comment{jabref-meta: databaseType:bibtex;}
